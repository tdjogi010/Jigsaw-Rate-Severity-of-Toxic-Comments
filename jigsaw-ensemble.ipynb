{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:16.927692Z","iopub.status.busy":"2022-02-03T19:10:16.927208Z","iopub.status.idle":"2022-02-03T19:10:17.503770Z","shell.execute_reply":"2022-02-03T19:10:17.503036Z","shell.execute_reply.started":"2022-02-03T19:10:16.927655Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import multiprocessing\n","from multiprocessing import Process, Queue\n","\n","\n","# from numba import cuda\n","# def free_gpu():\n","#     # cuda.select_device(0)\n","#     # cuda.close()\n","#     # cuda.select_device(0)\n","#     device = cuda.get_current_device()\n","#     device.reset()\n","\n","\n","# # free_gpu()"]},{"cell_type":"markdown","metadata":{},"source":["## BERT + 1/2 BiLSTM"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:17.505336Z","iopub.status.busy":"2022-02-03T19:10:17.505076Z","iopub.status.idle":"2022-02-03T19:10:23.649539Z","shell.execute_reply":"2022-02-03T19:10:23.647302Z","shell.execute_reply.started":"2022-02-03T19:10:17.505301Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import transformers\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import re\n","import emoji\n","import gc"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:23.657016Z","iopub.status.busy":"2022-02-03T19:10:23.654946Z","iopub.status.idle":"2022-02-03T19:10:23.665465Z","shell.execute_reply":"2022-02-03T19:10:23.664254Z","shell.execute_reply.started":"2022-02-03T19:10:23.656958Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["## Constants\n","target_key = \"score\"\n","text_key = \"text\" #\"txt\"\n","batch_size = 32\n","bert_path = \"bert-base-uncased\" # \"../input/bertbaseuncased/bert-base-uncased\" #\n","train_path = \"../input/clean-civil-data-jigsaw-downsampled/clean_civil.csv\"\n","lstm_hidden_dim = 64 # from 768 (bert) to 64  # the decrease is steep; u may lose info\n","dropout_rate = 0.3\n","output_dim = 1\n","max_length = 350\n","n_epochs = 1\n","checkpoint_filepath = \"./bert/ckpt-loss={loss:.5f}-epoch={epoch}-batch={batch}\"\n","save_after_batches = 5000\n","test_size_percent =  0.05\n","test_path = \"./train/comments_to_score.csv\" #\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\n","\n","## bert-1-bilstm ##\n","load_model_path = \"./output/bert-1-bilstm/bert/final_model\" #\"../input/jisaw-bert-1-bilstm-epoch-2-loss01263/final_model\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:23.668556Z","iopub.status.busy":"2022-02-03T19:10:23.668049Z","iopub.status.idle":"2022-02-03T19:10:23.829426Z","shell.execute_reply":"2022-02-03T19:10:23.828796Z","shell.execute_reply.started":"2022-02-03T19:10:23.668520Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["(7537, 2)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["comments_to_score_df = pd.read_csv(test_path)\n","comments_to_score_df.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:23.835043Z","iopub.status.busy":"2022-02-03T19:10:23.833168Z","iopub.status.idle":"2022-02-03T19:10:24.934678Z","shell.execute_reply":"2022-02-03T19:10:24.933834Z","shell.execute_reply.started":"2022-02-03T19:10:23.835006Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class CivilDataGenerator(tf.keras.utils.Sequence): # could optimize more like BucketIterator for padding\n","    def __init__(self, texts, scores, tokenizer, batch_size=batch_size, shuffle=True, include_targets=True): # texts -> numpy array\n","        self.texts = texts\n","        self.scores = scores\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        self.tokenizer =  tokenizer # \n","        self.indexes = np.arange(len(self.texts))\n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.texts) // self.batch_size + 1 if (len(self.texts) % self.batch_size) != 0 else 0\n","    \n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)\n","            \n","    def __getitem__(self, idx): # idx -> index batch\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        texts = self.texts[indexes]\n","        \n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            texts.tolist(), # num\n","            add_special_tokens=True, # not really needed in our case. \n","            max_length=max_length, # bert has 512 max length # providing our own\n","            return_attention_mask=True, # need bcos to pad to max length\n","            return_token_type_ids=False, # not needed # needed when u have two sentences\n","            padding='max_length', #pad_to_max_length=True, # needed\n","            return_tensors=\"tf\",\n","            truncation=True,\n","        )\n","        \n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        \n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            scores = np.array(self.scores[indexes], dtype=\"float32\")\n","            return [input_ids, attention_masks], scores\n","        else:\n","            return [input_ids, attention_masks]\n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:24.937129Z","iopub.status.busy":"2022-02-03T19:10:24.935944Z","iopub.status.idle":"2022-02-03T19:10:48.569666Z","shell.execute_reply":"2022-02-03T19:10:48.568920Z","shell.execute_reply.started":"2022-02-03T19:10:24.937093Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-02-04 01:32:19.805167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:19.826341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:19.826796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:19.827629: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-02-04 01:32:19.828954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:19.829297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:19.829611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:20.525457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:20.525802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:20.525814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2022-02-04 01:32:20.526092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:32:20.526123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5420 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"]}],"source":["# model = tf.keras.models.load_model(load_model_path)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:48.624748Z","iopub.status.busy":"2022-02-03T19:10:48.624488Z","iopub.status.idle":"2022-02-03T19:10:48.860367Z","shell.execute_reply":"2022-02-03T19:10:48.859633Z","shell.execute_reply.started":"2022-02-03T19:10:48.624718Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["tokenizer = transformers.BertTokenizer.from_pretrained(bert_path, do_lower_case=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:48.861942Z","iopub.status.busy":"2022-02-03T19:10:48.861682Z","iopub.status.idle":"2022-02-03T19:10:48.871359Z","shell.execute_reply":"2022-02-03T19:10:48.870005Z","shell.execute_reply.started":"2022-02-03T19:10:48.861909Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["test_data = CivilDataGenerator(\n","    comments_to_score_df[text_key].values,\n","    None, # no target while inferring\n","    tokenizer,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    include_targets=False # added for inference\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:10:48.873264Z","iopub.status.busy":"2022-02-03T19:10:48.872858Z","iopub.status.idle":"2022-02-03T19:12:58.173728Z","shell.execute_reply":"2022-02-03T19:12:58.173029Z","shell.execute_reply.started":"2022-02-03T19:10:48.873226Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-02-04 01:33:58.048012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.068184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.068561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.069097: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-02-04 01:33:58.070235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.070559: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.070889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.763645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.764050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.764065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2022-02-04 01:33:58.764434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-04 01:33:58.764568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5420 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n","2022-02-04 01:34:05.334234: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2022-02-04 01:34:07.094571: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","2022-02-04 01:34:08.394468: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"]},{"name":"stdout","output_type":"stream","text":["236/236 [==============================] - ETA: 12:5 - ETA: 1:4 - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 59s - ETA: 59 - ETA: 59 - ETA: 58 - ETA: 58 - ETA: 57 - ETA: 57 - ETA: 56 - ETA: 56 - ETA: 56 - ETA: 55 - ETA: 55 - ETA: 54 - ETA: 54 - ETA: 53 - ETA: 53 - ETA: 53 - ETA: 52 - ETA: 52 - ETA: 51 - ETA: 51 - ETA: 50 - ETA: 50 - ETA: 50 - ETA: 49 - ETA: 49 - ETA: 48 - ETA: 48 - ETA: 48 - ETA: 47 - ETA: 47 - ETA: 46 - ETA: 46 - ETA: 45 - ETA: 45 - ETA: 45 - ETA: 44 - ETA: 44 - ETA: 43 - ETA: 43 - ETA: 42 - ETA: 42 - ETA: 42 - ETA: 41 - ETA: 41 - ETA: 40 - ETA: 40 - ETA: 40 - ETA: 39 - ETA: 39 - ETA: 38 - ETA: 38 - ETA: 37 - ETA: 37 - ETA: 37 - ETA: 36 - ETA: 36 - ETA: 35 - ETA: 35 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 102s 421ms/step\n"]}],"source":["# with tf.device('/device:GPU:0'):\n","#     bert_1_biLstm = model.predict(\n","#         test_data,\n","#         use_multiprocessing=True, # can only be used when x, y are generators\n","#         workers=-1,\n","#         verbose=1,\n","#     )\n","\n","# bert_1_biLstm\n","\n","def evaluate(test_data, queue):\n","    model = tf.keras.models.load_model(load_model_path)\n","    with tf.device('/device:GPU:0'):\n","        preds = model.predict(\n","            test_data,\n","            use_multiprocessing=True, # can only be used when x, y are generators\n","            workers=-1,\n","            verbose=1,\n","        )\n","    queue.put(preds)\n","\n","q = Queue()\n","process_eval = multiprocessing.Process(target=evaluate, args=(test_data, q))\n","process_eval.start()\n","process_eval.join()\n","bert_1_biLstm = q.get()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["array([[0.1559605 ],\n","       [0.14655367],\n","       [0.6794217 ],\n","       ...,\n","       [0.34467226],\n","       [1.29173   ],\n","       [0.29447895]], dtype=float32)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["bert_1_biLstm"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:12:58.176567Z","iopub.status.busy":"2022-02-03T19:12:58.176364Z","iopub.status.idle":"2022-02-03T19:12:59.624646Z","shell.execute_reply":"2022-02-03T19:12:59.623856Z","shell.execute_reply.started":"2022-02-03T19:12:58.176542Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["4"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# del model\n","gc.collect()"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:12:59.626277Z","iopub.status.busy":"2022-02-03T19:12:59.626036Z","iopub.status.idle":"2022-02-03T19:13:22.766420Z","shell.execute_reply":"2022-02-03T19:13:22.765697Z","shell.execute_reply.started":"2022-02-03T19:12:59.626243Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["## bert-2-bilstm ##\n","load_model_path = \"./output/bert-2-bilstm/bert/final_model\" #\"../input/jisaw-bert-2-bilstm-epoch2-loss-011490/final_model\"\n","model = tf.keras.models.load_model(load_model_path)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:13:22.843004Z","iopub.status.busy":"2022-02-03T19:13:22.842747Z","iopub.status.idle":"2022-02-03T19:15:33.602308Z","shell.execute_reply":"2022-02-03T19:15:33.601625Z","shell.execute_reply.started":"2022-02-03T19:13:22.842957Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["236/236 [==============================] - 121s 507ms/step\n"]},{"data":{"text/plain":["array([[0.25757378],\n","       [0.12379802],\n","       [0.7542055 ],\n","       ...,\n","       [0.2717326 ],\n","       [1.7095122 ],\n","       [0.35591382]], dtype=float32)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["with tf.device('/device:GPU:0'):\n","    bert_2_biLstm = model.predict(\n","        test_data,\n","        use_multiprocessing=True, # can only be used when x, y are generators\n","        workers=-1,\n","        verbose=1,\n","    )\n","\n","bert_2_biLstm"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:33.606421Z","iopub.status.busy":"2022-02-03T19:15:33.606001Z","iopub.status.idle":"2022-02-03T19:15:36.368587Z","shell.execute_reply":"2022-02-03T19:15:36.367839Z","shell.execute_reply.started":"2022-02-03T19:15:33.606390Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["603828"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["del model, test_data\n","# free_gpu()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## UnitaryAI"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.371780Z","iopub.status.busy":"2022-02-03T19:15:36.371579Z","iopub.status.idle":"2022-02-03T19:15:36.375385Z","shell.execute_reply":"2022-02-03T19:15:36.374678Z","shell.execute_reply.started":"2022-02-03T19:15:36.371755Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.377340Z","iopub.status.busy":"2022-02-03T19:15:36.376837Z","iopub.status.idle":"2022-02-03T19:15:36.399636Z","shell.execute_reply":"2022-02-03T19:15:36.398898Z","shell.execute_reply.started":"2022-02-03T19:15:36.377305Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["import torch\n","import transformers\n","\n","MODEL_URLS = {\n","    \"original\": \"https://github.com/unitaryai/detoxify/releases/download/v0.1-alpha/toxic_original-c1212f89.ckpt\",\n","    \"unbiased\": \"https://github.com/unitaryai/detoxify/releases/download/v0.3-alpha/toxic_debiased-c7548aa0.ckpt\",\n","    \"multilingual\": \"https://github.com/unitaryai/detoxify/releases/download/v0.4-alpha/multilingual_debiased-0b549669.ckpt\"\n","}\n","\n","PRETRAINED_MODEL = None\n","\n","\n","def get_model_and_tokenizer(\n","    model_type, model_name, tokenizer_name, num_classes, state_dict, huggingface_config_path=None\n","):\n","    print(model_name)\n","    model_class = getattr(transformers, model_name)\n","    model = model_class.from_pretrained(\n","        pretrained_model_name_or_path=None,\n","        config=huggingface_config_path or model_type,\n","        num_labels=num_classes,\n","        state_dict=state_dict,\n","        local_files_only=huggingface_config_path is not None,\n","    )\n","    tokenizer = getattr(transformers, tokenizer_name).from_pretrained(\n","        huggingface_config_path or model_type,\n","        local_files_only=huggingface_config_path is not None,\n","        # TODO: may be needed to let it work with Kaggle competition\n","        model_max_length=512,\n","    )\n","\n","    return model, tokenizer\n","\n","\n","def load_checkpoint(model_type=\"original\", checkpoint=None, device='cuda', huggingface_config_path=None):\n","    if checkpoint is None:\n","        checkpoint_path = MODEL_URLS[model_type]\n","        loaded = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=device)\n","    else:\n","        loaded = torch.load(checkpoint)\n","        if \"config\" not in loaded or \"state_dict\" not in loaded:\n","            raise ValueError(\n","                \"Checkpoint needs to contain the config it was trained \\\n","                    with as well as the state dict\"\n","            )\n","    class_names = loaded[\"config\"][\"dataset\"][\"args\"][\"classes\"]\n","    # standardise class names between models\n","    change_names = {\n","        \"toxic\": \"toxicity\",\n","        \"identity_hate\": \"identity_attack\",\n","        \"severe_toxic\": \"severe_toxicity\",\n","    }\n","    class_names = [change_names.get(cl, cl) for cl in class_names]\n","    model, tokenizer = get_model_and_tokenizer(\n","        **loaded[\"config\"][\"arch\"][\"args\"], state_dict=loaded[\"state_dict\"], huggingface_config_path=huggingface_config_path,\n","    )\n","\n","    return model, tokenizer, class_names\n","\n","\n","def load_model(model_type, checkpoint=None):\n","    if checkpoint is None:\n","        model, _, _ = load_checkpoint(model_type=model_type)\n","    else:\n","        model, _, _ = load_checkpoint(checkpoint=checkpoint)\n","    return model\n","\n","\n","class Detoxify:\n","    \"\"\"Detoxify\n","    Easily predict if a comment or list of comments is toxic.\n","    Can initialize 5 different model types from model type or checkpoint path:\n","        - original:\n","            model trained on data from the Jigsaw Toxic Comment\n","            Classification Challenge\n","        - unbiased:\n","            model trained on data from the Jigsaw Unintended Bias in\n","            Toxicity Classification Challenge\n","        - multilingual:\n","            model trained on data from the Jigsaw Multilingual\n","            Toxic Comment Classification Challenge\n","        - original-small:\n","            lightweight version of the original model\n","        - unbiased-small:\n","            lightweight version of the unbiased model\n","    Args:\n","        model_type(str): model type to be loaded, can be either original,\n","                         unbiased or multilingual\n","        checkpoint(str): checkpoint path, defaults to None\n","        device(str or torch.device): accepts any torch.device input or \n","                                     torch.device object, defaults to cpu\n","        huggingface_config_path: path to HF config and tokenizer files needed for offline model loading\n","    Returns:\n","        results(dict): dictionary of output scores for each class\n","    \"\"\"\n","\n","    def __init__(self, model_type=\"original\", checkpoint=PRETRAINED_MODEL, device=\"cuda\", huggingface_config_path=None):\n","        super(Detoxify, self).__init__()\n","        self.model, self.tokenizer, self.class_names = load_checkpoint(\n","            model_type=model_type, checkpoint=checkpoint, device=device, huggingface_config_path=huggingface_config_path,\n","        )\n","        self.device = device\n","        self.model.to(self.device)\n","\n","    @torch.no_grad()\n","    def predict(self, text):\n","        self.model.eval()\n","        inputs = self.tokenizer(\n","            text, return_tensors=\"pt\", truncation=True, padding=True\n","        ).to(self.model.device)\n","        out = self.model(**inputs)[0]\n","        scores = torch.sigmoid(out).cpu().detach().numpy()\n","        results = {}\n","        for i, cla in enumerate(self.class_names):\n","            results[cla] = (\n","                scores[0][i]\n","                if isinstance(text, str)\n","                else [scores[ex_i][i].tolist() for ex_i in range(len(scores))]\n","            )\n","        return results\n","\n","\n","def toxic_bert():\n","    return load_model(\"original\")\n","\n","\n","def toxic_albert():\n","    return load_model(\"original-small\")\n","\n","\n","def unbiased_toxic_roberta():\n","    return load_model(\"unbiased\")\n","\n","\n","def unbiased_albert():\n","    return load_model(\"unbiased-small\")\n","\n","\n","def multilingual_toxic_xlm_r():\n","    return load_model(\"multilingual\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.401302Z","iopub.status.busy":"2022-02-03T19:15:36.401005Z","iopub.status.idle":"2022-02-03T19:15:36.411818Z","shell.execute_reply":"2022-02-03T19:15:36.411085Z","shell.execute_reply.started":"2022-02-03T19:15:36.401266Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["## constants \n","\n","## load Unitary AI models path ##\n","model_info_dict = {\n","    'original' : {\n","        \"checkpoint\":\"../input/jigsaw-unitary-ai-detoxify-and-models-ckpt/unitaryAI/toxic_original-c1212f89.ckpt\", \"huggingface_config_path\": \"../input/jigsaw-unitary-ai-detoxify-and-models-ckpt/unitaryAI/bert-base-uncased\"\n","    },\n","    'unbiased' : {\n","        \"checkpoint\":\"../input/jigsaw-unitary-ai-detoxify-and-models-ckpt/unitaryAI/toxic_debiased-c7548aa0.ckpt\", \"huggingface_config_path\":\"../input/jigsaw-unitary-ai-detoxify-and-models-ckpt/unitaryAI/roberta-base\"\n","    },\n","    \"multilingual\" : {\n","        \"checkpoint\":\"../input/jigsaw-unitary-ai-detoxify-and-models-ckpt/unitaryAI/multilingual_debiased-0b549669.ckpt\",\"huggingface_config_path\": \"../input/jigsaw-unitary-ai-detoxify-and-models-ckpt/unitaryAI/xlm-roberta-base\"\n","    }\n","}\n","\n","test_data_path = \"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\"\n","val_data_path = \"../input/jigsaw-toxic-severity-rating/validation_data.csv\"\n","comment_key = \"text\"\n","comment_id_key = \"comment_id\"\n","batch_size = 32\n","target_key = \"score\""]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.413479Z","iopub.status.busy":"2022-02-03T19:15:36.413228Z","iopub.status.idle":"2022-02-03T19:15:36.425024Z","shell.execute_reply":"2022-02-03T19:15:36.424143Z","shell.execute_reply.started":"2022-02-03T19:15:36.413446Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["whole_df = comments_to_score_df\n","whole_df.shape"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.426849Z","iopub.status.busy":"2022-02-03T19:15:36.426599Z","iopub.status.idle":"2022-02-03T19:15:36.433889Z","shell.execute_reply":"2022-02-03T19:15:36.432989Z","shell.execute_reply.started":"2022-02-03T19:15:36.426817Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, comments, targets, include_target=True):\n","        self.comments = comments\n","        self.targets = targets\n","        self.include_target = include_target\n","    \n","    def __len__(self):\n","        return self.comments.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        comment = self.comments[idx]\n","        if self.include_target == True:\n","            return comment, self.targets[idx]\n","        else:\n","            return comment\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.436144Z","iopub.status.busy":"2022-02-03T19:15:36.435918Z","iopub.status.idle":"2022-02-03T19:15:36.443615Z","shell.execute_reply":"2022-02-03T19:15:36.442893Z","shell.execute_reply.started":"2022-02-03T19:15:36.436120Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["pytorch_dataset = CustomDataset(whole_df[comment_key].values, None, include_target=False)\n","test_dataloader = DataLoader(pytorch_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:15:36.445031Z","iopub.status.busy":"2022-02-03T19:15:36.444640Z","iopub.status.idle":"2022-02-03T19:16:03.015467Z","shell.execute_reply":"2022-02-03T19:16:03.014685Z","shell.execute_reply.started":"2022-02-03T19:15:36.444912Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["models = []\n","for i, model_name in enumerate(model_info_dict):\n","    model = Detoxify(model_name, checkpoint=model_info_dict[model_name][\"checkpoint\"], huggingface_config_path=model_info_dict[model_name][\"huggingface_config_path\"])\n","    models.append(model)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:16:03.017011Z","iopub.status.busy":"2022-02-03T19:16:03.016736Z","iopub.status.idle":"2022-02-03T19:22:25.527440Z","shell.execute_reply":"2022-02-03T19:22:25.526736Z","shell.execute_reply.started":"2022-02-03T19:16:03.016964Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["unitAI_preds = np.zeros((whole_df.shape[0], len(model_info_dict)))\n","for i, model_name in enumerate(model_info_dict):\n","    model = models[i] #Detoxify(model_name, checkpoint=model_info_dict[model_name][\"checkpoint\"], huggingface_config_path=model_info_dict[model_name][\"huggingface_config_path\"])\n","    lastidx=0\n","    for texts in tqdm(test_dataloader):\n","        preds_dict = model.predict(texts) # could do combination of weights here as well\n","        # print(preds_dict)\n","        for key in preds_dict:\n","            unitAI_preds[lastidx: lastidx+len(texts), i]+=preds_dict[key]\n","        \n","        lastidx+=len(texts)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.529291Z","iopub.status.busy":"2022-02-03T19:22:25.528584Z","iopub.status.idle":"2022-02-03T19:22:25.536280Z","shell.execute_reply":"2022-02-03T19:22:25.535322Z","shell.execute_reply.started":"2022-02-03T19:22:25.529252Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["unitAI_preds, unitAI_preds.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.538221Z","iopub.status.busy":"2022-02-03T19:22:25.537830Z","iopub.status.idle":"2022-02-03T19:22:25.803583Z","shell.execute_reply":"2022-02-03T19:22:25.801359Z","shell.execute_reply.started":"2022-02-03T19:22:25.538183Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["del models, pytorch_dataset, test_dataloader\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["## BILSTM | ruddit_only"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.805817Z","iopub.status.busy":"2022-02-03T19:22:25.805303Z","iopub.status.idle":"2022-02-03T19:22:25.815677Z","shell.execute_reply":"2022-02-03T19:22:25.815027Z","shell.execute_reply.started":"2022-02-03T19:22:25.805774Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# del comments_to_score_df\n","# gc.collect()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.818533Z","iopub.status.busy":"2022-02-03T19:22:25.817202Z","iopub.status.idle":"2022-02-03T19:22:25.830312Z","shell.execute_reply":"2022-02-03T19:22:25.829215Z","shell.execute_reply.started":"2022-02-03T19:22:25.818496Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# import pandas as pd\n","# import numpy as np\n","# import torch\n","# from torchtext import vocab\n","# from torchtext.legacy import data, datasets\n","# from torchtext.legacy.data import BucketIterator, TabularDataset , Dataset\n","# from torch.utils.data import Sampler, Subset#, Dataset\n","# from typing import Sequence, Optional\n","# from torch import nn\n","# from sklearn.model_selection import KFold\n","# from tqdm import tqdm"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.832447Z","iopub.status.busy":"2022-02-03T19:22:25.832044Z","iopub.status.idle":"2022-02-03T19:22:25.845127Z","shell.execute_reply":"2022-02-03T19:22:25.843783Z","shell.execute_reply.started":"2022-02-03T19:22:25.832409Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.847140Z","iopub.status.busy":"2022-02-03T19:22:25.846407Z","iopub.status.idle":"2022-02-03T19:22:25.861380Z","shell.execute_reply":"2022-02-03T19:22:25.858384Z","shell.execute_reply.started":"2022-02-03T19:22:25.847105Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# ## Constants ##\n","# comment_key = \"txt\"\n","# target_key = \"score\"\n","# train_data_path = \"./train/clean_ruddit_with_text.csv\"\n","# embedding_name = \"glove.840B.300d\" #\"glove.6B.100d\"\n","# embedding_dim = 300 # 100\n","# hidden_dim = 256\n","# output_dim = 1\n","# n_layers = 2\n","# k_folds = 5\n","# n_epochs = 7\n","# batch_size = 256\n","# dropout_rate = 0.5\n","# output_model_path = \"./output/bilstm_ruddit_only/model_%s_%s\" #\"./output/bilstm_civil_only/model_%s_%s\" # loss, more info"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.862631Z","iopub.status.busy":"2022-02-03T19:22:25.862375Z","iopub.status.idle":"2022-02-03T19:22:25.873441Z","shell.execute_reply":"2022-02-03T19:22:25.872764Z","shell.execute_reply.started":"2022-02-03T19:22:25.862597Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# class BiLSTM(nn.Module):\n","#     def __init__(self, embedding_vocab: vocab, hidden_dim: int, output_dim: int, n_layers: int, # vocab_size: int, embedding_dim: int\n","#         bidirectional: bool, dropout: float, pad_idx: Optional[int]):\n","#         super().__init__()\n","#         vocab_size, embedding_dim = embedding_vocab.vectors.size()\n","#         self.embedding_layer = nn.Embedding.from_pretrained(embedding_vocab.vectors, freeze=True, padding_idx=pad_idx) # not training embeddding\n","#         # self.embedding_layer =  nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","#         self.lstm = nn.LSTM(embedding_dim,\n","#                            hidden_dim,\n","#                            num_layers=n_layers,\n","#                            bidirectional=bidirectional,\n","#                            batch_first=True, # imp\n","#                            dropout=dropout)\n","#         self.fc = nn.Linear(hidden_dim * 2, output_dim) # bcos birectional\n","#         self.dropout_emb = nn.Dropout(dropout) # not sure if same layer object can be used\n","#         self.dropout_fc = nn.Dropout(dropout)\n"," \n","#     def forward(self, text, examples_lengths): # text is already padded\n","#         embedded = self.dropout_emb(self.embedding_layer(text))\n","#         pack_out = nn.utils.rnn.pack_padded_sequence(embedded, examples_lengths.cpu(), batch_first=True)#.to(device)\n","#         out_lstm, (hidden, cell) = self.lstm(embedded) # hidden -> (D∗num_layers, batch , hidden_dim) # D = 2 if bidirectional=True otherwise 1\n","#         h1, h2 = hidden[-2, :, :], hidden[-1, :, :]# -2, -1 is taking last hidden state (twice bcos bidirectional) # so h1,h2 -> (batch, hidden_dim)\n","#         x = self.dropout_fc(torch.cat((h1, h2), dim=1)) # concatenate along hidden_dim # x -> (batch, hidden_dim*2)\n","#         return self.fc(x) # feel like too many dropouts\n"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.875157Z","iopub.status.busy":"2022-02-03T19:22:25.874699Z","iopub.status.idle":"2022-02-03T19:22:25.879121Z","shell.execute_reply":"2022-02-03T19:22:25.878309Z","shell.execute_reply.started":"2022-02-03T19:22:25.875122Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# model_load_paths = [\"../input/bilstm-ruddit-only/bilstm_not_clean_ruddit_only/bilstm_not_clean_ruddit_only/model_0.07617800012230873_fold_4\",\n","#                     \"../input/bilstm-ruddit-only/bilstm_not_clean_ruddit_only/bilstm_not_clean_ruddit_only/model_0.08099494650959968_fold_1\",\n","#                    \"../input/bilstm-ruddit-only/bilstm_not_clean_ruddit_only/bilstm_not_clean_ruddit_only/model_0.08217549547553063_fold_0\",\n","#                    \"../input/bilstm-ruddit-only/bilstm_not_clean_ruddit_only/bilstm_not_clean_ruddit_only/model_0.08438036367297172_fold_3\",\n","#                    \"../input/bilstm-ruddit-only/bilstm_not_clean_ruddit_only/bilstm_not_clean_ruddit_only/model_0.09249704629182816_fold_2\",\n","#                    ]\n","# vocab_path = \"../input/bilstm-ruddit-only/bilstm_not_clean_ruddit_only/bilstm_not_clean_ruddit_only/ruddit_vocab\""]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.881633Z","iopub.status.busy":"2022-02-03T19:22:25.881029Z","iopub.status.idle":"2022-02-03T19:22:25.900518Z","shell.execute_reply":"2022-02-03T19:22:25.899728Z","shell.execute_reply.started":"2022-02-03T19:22:25.881596Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# text_field = torch.load(vocab_path) # dont build_vocab now"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.904080Z","iopub.status.busy":"2022-02-03T19:22:25.903783Z","iopub.status.idle":"2022-02-03T19:22:25.916253Z","shell.execute_reply":"2022-02-03T19:22:25.909392Z","shell.execute_reply.started":"2022-02-03T19:22:25.904046Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# models = []\n","# for model_path in model_load_paths:\n","#     model = BiLSTM(text_field.vocab, hidden_dim, output_dim=1, n_layers=n_layers, bidirectional=True, dropout=dropout_rate, pad_idx=text_field.vocab.stoi[text_field.pad_token])\n","#     model.load_state_dict(torch.load(model_path, map_location=device))\n","#     models.append(model)\n","    \n","# models"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.917730Z","iopub.status.busy":"2022-02-03T19:22:25.917501Z","iopub.status.idle":"2022-02-03T19:22:25.926567Z","shell.execute_reply":"2022-02-03T19:22:25.925158Z","shell.execute_reply.started":"2022-02-03T19:22:25.917693Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# comment_id_field = data.Field(dtype=torch.int64, batch_first=True, sequential=False, use_vocab=False, preprocessing=int)\n","# fields = [('comment_id', comment_id_field), ('text', text_field)]\n","# fields"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.928124Z","iopub.status.busy":"2022-02-03T19:22:25.927877Z","iopub.status.idle":"2022-02-03T19:22:25.935460Z","shell.execute_reply":"2022-02-03T19:22:25.933657Z","shell.execute_reply.started":"2022-02-03T19:22:25.928092Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# comments_to_score = TabularDataset(\n","#     path=\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\",\n","#     format='csv',\n","#     fields=fields,\n","#     skip_header=True,\n","# )\n","# len(comments_to_score.examples)"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.937058Z","iopub.status.busy":"2022-02-03T19:22:25.936799Z","iopub.status.idle":"2022-02-03T19:22:25.945911Z","shell.execute_reply":"2022-02-03T19:22:25.944311Z","shell.execute_reply.started":"2022-02-03T19:22:25.937023Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# test_iter, = BucketIterator.splits((comments_to_score,),\n","#                                 sort_key=lambda x: len(x.text),  # sort by s attribute (quote)\n","#                                 sort_within_batch=True,\n","#                                 batch_size=32,\n","#                                 device=device)"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.947816Z","iopub.status.busy":"2022-02-03T19:22:25.947512Z","iopub.status.idle":"2022-02-03T19:22:25.952239Z","shell.execute_reply":"2022-02-03T19:22:25.951337Z","shell.execute_reply.started":"2022-02-03T19:22:25.947783Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# bilstm_ruddit_only_pred = np.zeros((len(comments_to_score.examples), len(models))) # (examples, models)\n","# comment_id_list = []\n","# last_idx = 0\n","# for batch in tqdm(test_iter):\n","#     text, examples_len = batch.text\n","#     batch_len = len(text)\n","#     for i, model in enumerate(models):\n","#         model.to(device)\n","#         preds = model(text, examples_len)\n","#         preds = torch.sigmoid(preds) # not necessary since ranking is needed\n","#         bilstm_ruddit_only_pred[last_idx:last_idx + batch_len, i] = preds.squeeze(1).cpu().detach().numpy() # alternating between gpu and cpu # better would be all gpu and then cpu\n","# #         model.to('cpu')\n","#     comment_id_list.extend(batch.comment_id.cpu().detach().numpy())\n","#     last_idx += batch_len\n","# #     print(text) # many out of vocab :/\n","\n","# len(comment_id_list), bilstm_ruddit_only_pred.shape"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.955068Z","iopub.status.busy":"2022-02-03T19:22:25.953980Z","iopub.status.idle":"2022-02-03T19:22:25.962971Z","shell.execute_reply":"2022-02-03T19:22:25.962131Z","shell.execute_reply.started":"2022-02-03T19:22:25.955028Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# # works!!!\n","# del models, comments_to_score, test_iter\n","# torch.cuda.empty_cache()\n","# gc.collect()"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.964558Z","iopub.status.busy":"2022-02-03T19:22:25.964309Z","iopub.status.idle":"2022-02-03T19:22:25.971193Z","shell.execute_reply":"2022-02-03T19:22:25.970347Z","shell.execute_reply.started":"2022-02-03T19:22:25.964525Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# bilstm_ruddit_only_df = pd.DataFrame({\"comment_id\": comment_id_list, \"score\": np.mean(bilstm_ruddit_only_pred, axis=1)}).sort_values(by=[\"comment_id\"])\n","# bert_1_biLstm_df = pd.DataFrame({\"comment_id\": comments_to_score_df[\"comment_id\"].values, \"score\": bert_1_biLstm.squeeze(1)}).sort_values(by=[\"comment_id\"])\n","# bert_2_biLstm_df = pd.DataFrame({\"comment_id\": comments_to_score_df[\"comment_id\"].values, \"score\": bert_2_biLstm.squeeze(1)}).sort_values(by=[\"comment_id\"])\n","# unitaryAI_original_df = pd.DataFrame({\"comment_id\": comments_to_score_df[\"comment_id\"].values, \"score\": unitAI_preds[:, 0]}).sort_values(by=[\"comment_id\"])\n","# unitaryAI_unbiased_df = pd.DataFrame({\"comment_id\": comments_to_score_df[\"comment_id\"].values, \"score\": unitAI_preds[:, 1]}).sort_values(by=[\"comment_id\"])\n","# unitaryAI_multilingual_df = pd.DataFrame({\"comment_id\": comments_to_score_df[\"comment_id\"].values, \"score\": unitAI_preds[:, 2]}).sort_values(by=[\"comment_id\"])\n","# bilstm_ruddit_only_df.shape, bert_1_biLstm_df.shape, bert_2_biLstm_df.shape, unitaryAI_original_df.shape, unitaryAI_unbiased_df.shape, unitaryAI_multilingual_df.shape"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.973355Z","iopub.status.busy":"2022-02-03T19:22:25.972459Z","iopub.status.idle":"2022-02-03T19:22:25.980595Z","shell.execute_reply":"2022-02-03T19:22:25.979839Z","shell.execute_reply.started":"2022-02-03T19:22:25.973318Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# # weights = {'bilstm_ruddit_only': 4.754776548389675, 'bert_1_bilstm': 0.0563325993719159, 'bert_2_bilstm': 0.0005159065135504051, 'multilingual': 0.08595313014460652, 'original': 0.10773060655864747, 'unbiased': 0.034223939582444046}\n","# weights = {'bert_1_bilstm': 0.2720956202305736, 'bert_2_bilstm': 1.3682913017691893, 'multilingual': 1.3008939861065933, 'original': 1.5262021808926747, 'unbiased': 1.8944012148054452}\n","# models_preds = {\n","# #     'bilstm_ruddit_only': bilstm_ruddit_only_df,\n","#     'bert_1_bilstm': bert_1_biLstm_df,\n","#     'bert_2_bilstm': bert_2_biLstm_df,\n","#     'multilingual': unitaryAI_multilingual_df,\n","#     'original': unitaryAI_original_df,\n","#     'unbiased': unitaryAI_unbiased_df, \n","# } # same keys"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.982622Z","iopub.status.busy":"2022-02-03T19:22:25.981825Z","iopub.status.idle":"2022-02-03T19:22:25.987912Z","shell.execute_reply":"2022-02-03T19:22:25.987109Z","shell.execute_reply.started":"2022-02-03T19:22:25.982586Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["# final_scores = np.zeros(len(comments_to_score_df))\n","# for key in models_preds:\n","#     final_scores += models_preds[key][\"score\"] #* weights[key]\n","    \n","# final_scores"]},{"cell_type":"markdown","metadata":{},"source":["## Ensemble Tuning"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:25.999689Z","iopub.status.busy":"2022-02-03T19:22:25.997371Z","iopub.status.idle":"2022-02-03T19:22:26.004304Z","shell.execute_reply":"2022-02-03T19:22:26.003400Z","shell.execute_reply.started":"2022-02-03T19:22:25.999542Z"},"trusted":true},"outputs":[],"source":["free_gpu()"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:22:26.008370Z","iopub.status.busy":"2022-02-03T19:22:26.007164Z","iopub.status.idle":"2022-02-03T19:22:26.016172Z","shell.execute_reply":"2022-02-03T19:22:26.014225Z","shell.execute_reply.started":"2022-02-03T19:22:26.008331Z"},"trusted":true},"outputs":[],"source":["# np."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:23:29.125120Z","iopub.status.busy":"2022-02-03T19:23:29.124767Z","iopub.status.idle":"2022-02-03T19:23:29.192899Z","shell.execute_reply":"2022-02-03T19:23:29.191959Z","shell.execute_reply.started":"2022-02-03T19:23:29.125028Z"},"trusted":true},"outputs":[],"source":["all_preds = np.vstack((bert_1_biLstm.squeeze(1), bert_2_biLstm.squeeze(1), unitAI_preds[:, 0], unitAI_preds[:, 1], unitAI_preds[:, 2]))\n","all_preds = all_preds.T\n","all_preds.shape\n","# all_preds[:,2], unitAI_preds[:, 0] # cross check"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-02-03T19:23:07.727093Z","iopub.status.busy":"2022-02-03T19:23:07.726376Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","model = tf.keras.models.load_model(\"./output/ensemble-nn-tuning/final_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:22:26.024455Z","iopub.status.idle":"2022-02-03T19:22:26.026636Z","shell.execute_reply":"2022-02-03T19:22:26.025942Z","shell.execute_reply.started":"2022-02-03T19:22:26.025914Z"},"trusted":true},"outputs":[],"source":["with tf.device('/device:GPU:0'):\n","    final_scores = model.predict(all_preds).squeeze(1)\n","    \n","final_scores.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-02-03T19:22:26.027564Z","iopub.status.idle":"2022-02-03T19:22:26.029389Z","shell.execute_reply":"2022-02-03T19:22:26.029161Z","shell.execute_reply.started":"2022-02-03T19:22:26.029134Z"},"trusted":true},"outputs":[],"source":["final_submission_df = pd.DataFrame({\"comment_id\": bilstm_ruddit_only_df[\"comment_id\"], \"score\": final_scores})\n","print(final_submission_df.shape)\n","final_submission_df.to_csv(\"submission.csv\", index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":4}
