{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow_ranking as tfr\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm \n",
    "# import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## constants ##\n",
    "test_size_percent = 0.2 # 20% test/val data\n",
    "val_data_path = \"./train/validation_data.csv\"\n",
    "more_toxic_key = \"more_toxic\"\n",
    "less_toxic_key = \"less_toxic\"\n",
    "dense_dim = 768\n",
    "hidden_dim = dense_dim*3 # 3 models\n",
    "batch_size=32\n",
    "\n",
    "margin = 0.5 # maybe less\n",
    "log_dir = \"./log/unitaryAI-dense-layer-ensemble/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30108, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = pd.read_csv(val_data_path)\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30108, 3, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./output/unitaryAI_validation_data_dense_output.npy', 'rb') as f:\n",
    "    dense_output = np.load(f)\n",
    "\n",
    "dense_output.shape #  (dataloaders, examples, models, dense_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 30108, 2304)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_output =  np.concatenate([dense_output[:, :, 0, :], dense_output[:, :, 1, :], dense_output[:, :, 2, :]], axis=-1)\n",
    "combined_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24086, 6022)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ind, val_ind = train_test_split(list(range(combined_output.shape[1])) ,test_size = test_size_percent, random_state = 2343)\n",
    "len(tr_ind), len(val_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross check\n",
    "# print(dense_output[0, 0, 0, :5])\n",
    "# print(dense_output[0, 0, 1, :5])\n",
    "# print(dense_output[0, 0, 2, :5])\n",
    "\n",
    "# print(\"idx 1\")\n",
    "# print(dense_output[1, 0, 0, :5])\n",
    "# print(dense_output[1, 0, 1, :5])\n",
    "# print(dense_output[1, 0, 2, :5])\n",
    "\n",
    "# model_idx = 2\n",
    "# combined_output[0, 0, model_idx*dense_dim: model_idx*dense_dim + 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedEmbeddingGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, less_toxic_combined_embeddings, more_toxic_combined_embeddings,  batch_size=batch_size, shuffle=True):\n",
    "        self.less_toxic_combined_embeddings = less_toxic_combined_embeddings\n",
    "        self.more_toxic_combined_embeddings = more_toxic_combined_embeddings\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        self.indexes = np.arange(len(self.less_toxic_combined_embeddings))\n",
    "        self.on_epoch_end() # shuffle once\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.less_toxic_combined_embeddings) // self.batch_size + 1 if (len(self.less_toxic_combined_embeddings) % self.batch_size) != 0 else 0\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, idx): # idx -> index batch\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        less_toxic_combined_embeddings = tf.convert_to_tensor(self.less_toxic_combined_embeddings[indexes], dtype=tf.float64)\n",
    "        more_toxic_combined_embeddings = tf.convert_to_tensor(self.more_toxic_combined_embeddings[indexes], dtype=tf.float64)\n",
    "        # targets = tf.convert_to_tensor([-1]*len(indexes), dtype=tf.float32) # for pytorch marginranking loss\n",
    "        targets = tf.convert_to_tensor([[0, 1]]*len(indexes), dtype=tf.float32) # for tfr.keras.losses.PairwiseHingeLoss()\n",
    "\n",
    "        return [less_toxic_combined_embeddings, more_toxic_combined_embeddings], targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_embeddings_train = CombinedEmbeddingGenerator(combined_output[0, tr_ind, :], combined_output[1, tr_ind, :]) # tr_ind\n",
    "\n",
    "combined_embeddings_val = CombinedEmbeddingGenerator(combined_output[0, val_ind, :], combined_output[1, val_ind, :]) # val_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModels():\n",
    "\n",
    "    def loss(margin=1):  # https://keras.io/examples/vision/siamese_contrastive/\n",
    "        # def contrastive_loss(y_true, y_pred):\n",
    "        #     print(y_true, y_pred)\n",
    "        #     square_pred = tf.math.square(y_pred)\n",
    "        #     margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
    "        #     return tf.math.reduce_mean(\n",
    "        #         (1 - y_true) * square_pred + (y_true) * margin_square\n",
    "        #     )\n",
    "\n",
    "        # return contrastive_loss\n",
    "        def margin_loss(y_true, diff):\n",
    "            # tf.print(\"y_true\", y_true, \"diff\", diff)\n",
    "            loss = tf.math.maximum( -y_true * diff + margin, 0)\n",
    "            # tf.print(\"loss\", loss)\n",
    "            return tf.math.reduce_mean(loss)\n",
    "\n",
    "        return margin_loss\n",
    "\n",
    "    input = layers.Input((combined_output.shape[-1],))\n",
    "    # print(\"tox_input\", input)\n",
    "    x = layers.Dense(combined_output.shape[-1], activation=\"tanh\")(input) # same size as input \n",
    "    x = layers.Dense(combined_output.shape[-1]//2, activation=\"tanh\")(x)\n",
    "    output = layers.Dense(1)(x) # toxicity score\n",
    "    # print(\"tox_output\", output)\n",
    "\n",
    "    tox_model = keras.Model(inputs=input, outputs=output)\n",
    "    tox_model.summary()\n",
    "\n",
    "\n",
    "    less_toxic_input = layers.Input((combined_output.shape[-1],))\n",
    "    more_toxic_input = layers.Input((combined_output.shape[-1],))\n",
    "\n",
    "    tower_1 = tox_model(less_toxic_input)\n",
    "    tower_2 = tox_model(more_toxic_input)\n",
    "    # merge_layer = tower_1 - tower_2\n",
    "    # siamese = keras.Model(inputs=[less_toxic_input, more_toxic_input], outputs=merge_layer) # try to separate predictions using our embeddings from unitary ai !\n",
    "    # siamese.compile(loss=loss(margin=margin), optimizer=tf.keras.optimizers.Adam(1e-4), metrics=[loss(margin=margin)])\n",
    "\n",
    "    merge_layer = tf.keras.layers.Concatenate(axis=-1,)([tower_1, tower_2])\n",
    "    siamese = keras.Model(inputs=[less_toxic_input, more_toxic_input], outputs=merge_layer)\n",
    "    siamese.compile(loss=tfr.keras.losses.PairwiseHingeLoss(), optimizer=tf.keras.optimizers.Adam(1e-4), )#metrics=[tfr.keras.losses.PairwiseHingeLoss()])\n",
    "    # siamese.summary()\n",
    "    return siamese, tox_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2304)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2304)              5310720   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1152)              2655360   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 7,967,233\n",
      "Trainable params: 7,967,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 23:58:33.580099: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:33.651045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:33.651521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:33.653135: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-06 23:58:33.654572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:33.654867: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:33.655153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:34.788517: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:34.788883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:34.788917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-02-06 23:58:34.789210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-02-06 23:58:34.789282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5420 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "siamese, tox_model = getModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 23:58:35.097972: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-02-06 23:58:35.098002: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-02-06 23:58:35.098987: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n",
      "2022-02-06 23:58:35.099689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2022-02-06 23:58:35.181961: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-02-06 23:58:35.182143: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
      "2022-02-06 23:58:35.267839: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/753 [..............................] - ETA: 2:08 - loss: 0.4785 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 23:58:37.092877: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-02-06 23:58:37.126608: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n",
      "2022-02-06 23:58:37.126658: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
      "2022-02-06 23:58:37.292957: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n",
      "2022-02-06 23:58:37.293837: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/753 [..............................] - ETA: 21s - loss: 0.5516"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-06 23:58:37.303369: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 139 callback api events and 134 activity events. \n",
      "2022-02-06 23:58:37.305332: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n",
      "2022-02-06 23:58:37.315194: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37\n",
      "\n",
      "2022-02-06 23:58:37.319294: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.trace.json.gz\n",
      "2022-02-06 23:58:37.328821: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37\n",
      "\n",
      "2022-02-06 23:58:37.331479: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.memory_profile.json.gz\n",
      "2022-02-06 23:58:37.345217: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37\n",
      "Dumped tool data for xplane.pb to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./log/unitaryAI-dense-layer-ensemble/train/plugins/profile/2022_02_06_23_58_37/DESKTOP-KPOCLK7.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "753/753 [==============================] - 12s 13ms/step - loss: 0.3498 - val_loss: 0.3311\n",
      "Epoch 2/10\n",
      "753/753 [==============================] - 9s 13ms/step - loss: 0.3366 - val_loss: 0.3279\n",
      "Epoch 3/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3362 - val_loss: 0.3284\n",
      "Epoch 4/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3355 - val_loss: 0.3350\n",
      "Epoch 5/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3349 - val_loss: 0.3288\n",
      "Epoch 6/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3350 - val_loss: 0.3312\n",
      "Epoch 7/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3343 - val_loss: 0.3266\n",
      "Epoch 8/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3343 - val_loss: 0.3274\n",
      "Epoch 9/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3331 - val_loss: 0.3259\n",
      "Epoch 10/10\n",
      "753/753 [==============================] - 10s 13ms/step - loss: 0.3329 - val_loss: 0.3283\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq=1)\n",
    "\n",
    "history = siamese.fit(\n",
    "    combined_embeddings_train, # target inside it\n",
    "    validation_data=combined_embeddings_val,\n",
    "    epochs=n_epochs,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAcc(preds_less_toxic, preds_more_toxic):\n",
    "    accuracy = np.sum((preds_more_toxic > preds_less_toxic))/preds_more_toxic.shape[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7143806044503487\n"
     ]
    }
   ],
   "source": [
    "# tox_model.predict(combined_embeddings_val)\n",
    "preds = np.zeros((len(val_ind), 2))\n",
    "lastidx = 0\n",
    "for batch in combined_embeddings_val:\n",
    "    less_tox, more_tox = batch[0][0], batch[0][1]\n",
    "    preds[lastidx: lastidx + len(less_tox), 0] = tox_model.predict(less_tox).squeeze(1)\n",
    "    preds[lastidx: lastidx + len(more_tox), 1] = tox_model.predict(more_tox).squeeze(1)\n",
    "    lastidx += len(less_tox)\n",
    "\n",
    "print(\"acc:\", calculateAcc(preds[:, 0], preds[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tox_model.save(\"./output/unitaryAI-dense-layer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGS ##\n",
    "\n",
    "1. v1 version: margin ranking from pytorch and distance as  simple diff. better than all my current models. weird thing : val_loss < train_loss. think valid_loss nad train_loss neeed to go down and can be improved \n",
    "\n",
    "loss: 0.3318 - margin_loss: 0.3318 - val_loss: 0.3283 - val_margin_loss: 0.3281 acc: 0.7163732979076719\n",
    "\n",
    "2. adding batch normalization between hidden dense layer 1 and 2 reduced train_loss 10 times but has worse effect on val_loss 3 times and reduced accuracy\n",
    "\n",
    "loss: 0.0300 - margin_loss: 0.0307 - val_loss: 1.0422 - val_margin_loss: 1.0428 acc: 0.617734971770176\n",
    "\n",
    "3. adding batch normalization after input reduced train_loss 10 times but  has worse effect on val_loss 3 times and reduced accuracy to half!\n",
    "\n",
    "loss: 0.0254 - margin_loss: 0.0254 - val_loss: 0.8329 - val_margin_loss: 0.8331 acc: 0.5059780803719695\n",
    "\n",
    "4. Both batch normalization -> way worse\n",
    "\n",
    "loss: 0.0226 - margin_loss: 0.0226 - val_loss: 2.2827 - val_margin_loss: 2.2818 acc: 0.4858850880106277\n",
    "\n",
    "NOTE: dont apply batch normalization to NLP ig (but good for images and cnn i think)\n",
    "\n",
    "5. changing the 2 hidden dense layer activation from relu to tanh didnt help. A bit better perf. \"\"\"Using tanh now\"\"\"\n",
    "\n",
    "loss: 0.3335 - margin_loss: 0.3335 - val_loss: 0.3306 - val_margin_loss: 0.3303 acc: 0.7178678180006642\n",
    "loss: 0.3331 - margin_loss: 0.3331 - val_loss: 0.3252 - val_margin_loss: 0.3248 acc: 0.7205247426104284\n",
    "\n",
    "6. adding one more dense layer with dense_dim//4 -> didnt help much. Total dense layer: 4\n",
    "\n",
    "loss: 0.3341 - margin_loss: 0.3342 - val_loss: 0.3298 - val_margin_loss: 0.3288 acc: 0.7196944536698772\n",
    "loss: 0.3341 - margin_loss: 0.3342 - val_loss: 0.3260 - val_margin_loss: 0.3250 acc: 0.7123879109930256\n",
    "\n",
    "7. remove one last hidden dense layer. -> didnt help Total dense layer: 2. Using 3 dense layer only\n",
    "loss: 0.3328 - margin_loss: 0.3328 - val_loss: 0.3293 - val_margin_loss: 0.3292 acc: 0.7122218532049153\n",
    "loss: 0.3319 - margin_loss: 0.3319 - val_loss: 0.3302 - val_margin_loss: 0.3293 acc: 0.7062437728329458\n",
    "after 20 epoch loss: 0.3281 - margin_loss: 0.3280 - val_loss: 0.3300 - val_margin_loss: 0.3295 acc: 0.7125539687811359\n",
    "\n",
    "8. Adding layer normalization between dense layer -> didnt help.\n",
    "\n",
    "loss: 0.3337 - margin_loss: 0.3337 - val_loss: 0.3279 - val_margin_loss: 0.3284  acc: 0.7165393556957821\n",
    "\n",
    "9. pytorch marginrank loss -> -1 (ie second input is greater)  (less_toxic, more_toxic)\n",
    "loss: 0.3334 - margin_loss: 0.3333 - val_loss: 0.3283 - val_margin_loss: 0.3282 acc: acc: 0.7155430089671205\n",
    "\n",
    "pytorch marginrank loss -> -1 (ie first input is greater)  (more_toxic, less_toxic, )\n",
    "\n",
    "loss: 0.3331 - margin_loss: 0.3331 - val_loss: 0.3286 - val_margin_loss: 0.3284 acc: 0.7168714712720027\n",
    "\n",
    "Note: custom marginranking loss is correct atleast\n",
    "\n",
    "10. Changed loss from pytorch margin ranking to tfr.keras.losses.PairwiseHingeLoss(). Looks more stable but less strict (less configurable) than the former.\n",
    "\n",
    "loss: 0.3331 - val_loss: 0.3270 acc: 0.7175357024244438\n",
    "after 20 epoch: loss: 0.3284 - val_loss: 0.3270 acc: 0.7186981069412155\n",
    "after 30 epoch: loss: 0.3243 - val_loss: 0.3261 acc: 0.7138824310860179\n",
    "\n",
    "10 epochs is good enough. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 2304)]            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2304)              5310720   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1152)              2655360   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 7,967,233\n",
      "Trainable params: 7,967,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "753/753 [==============================] - 10s 12ms/step - loss: 0.3492 - val_loss: 0.3378\n",
      "Epoch 2/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3354 - val_loss: 0.3396\n",
      "Epoch 3/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3347 - val_loss: 0.3347\n",
      "Epoch 4/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3343 - val_loss: 0.3333\n",
      "Epoch 5/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3336 - val_loss: 0.3329\n",
      "Epoch 6/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3329 - val_loss: 0.3338\n",
      "Epoch 7/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3324 - val_loss: 0.3352\n",
      "Epoch 8/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3316 - val_loss: 0.3320\n",
      "Epoch 9/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3310 - val_loss: 0.3329\n",
      "Epoch 10/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3313 - val_loss: 0.3416\n",
      "f 0 acc: 0.7147127200265693\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-07 00:02:03.519674: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./output/unitaryAI-dense-layer-v2/folds/model_0.7147127200265693_fold_0/assets\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 2304)]            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2304)              5310720   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1152)              2655360   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 7,967,233\n",
      "Trainable params: 7,967,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "753/753 [==============================] - 10s 12ms/step - loss: 0.3496 - val_loss: 0.3317\n",
      "Epoch 2/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3361 - val_loss: 0.3328\n",
      "Epoch 3/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3358 - val_loss: 0.3294\n",
      "Epoch 4/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3346 - val_loss: 0.3286\n",
      "Epoch 5/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3339 - val_loss: 0.3317\n",
      "Epoch 6/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3340 - val_loss: 0.3312\n",
      "Epoch 7/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3330 - val_loss: 0.3304\n",
      "Epoch 8/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3324 - val_loss: 0.3294\n",
      "Epoch 9/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3327 - val_loss: 0.3284\n",
      "Epoch 10/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3322 - val_loss: 0.3355\n",
      "f 1 acc: 0.7107273331119229\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./output/unitaryAI-dense-layer-v2/folds/model_0.7107273331119229_fold_1/assets\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 2304)]            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2304)              5310720   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1152)              2655360   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 7,967,233\n",
      "Trainable params: 7,967,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "753/753 [==============================] - 10s 12ms/step - loss: 0.3493 - val_loss: 0.3373\n",
      "Epoch 2/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3349 - val_loss: 0.3384\n",
      "Epoch 3/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3343 - val_loss: 0.3378\n",
      "Epoch 4/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3326 - val_loss: 0.3389\n",
      "Epoch 5/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3326 - val_loss: 0.3387\n",
      "Epoch 6/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3321 - val_loss: 0.3367\n",
      "Epoch 7/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3317 - val_loss: 0.3375\n",
      "Epoch 8/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3313 - val_loss: 0.3368\n",
      "Epoch 9/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3308 - val_loss: 0.3347\n",
      "Epoch 10/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3297 - val_loss: 0.3364\n",
      "f 2 acc: 0.7020923281301893\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./output/unitaryAI-dense-layer-v2/folds/model_0.7020923281301893_fold_2/assets\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        [(None, 2304)]            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2304)              5310720   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1152)              2655360   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 7,967,233\n",
      "Trainable params: 7,967,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "753/753 [==============================] - 10s 12ms/step - loss: 0.3478 - val_loss: 0.3360\n",
      "Epoch 2/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3354 - val_loss: 0.3365\n",
      "Epoch 3/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3347 - val_loss: 0.3350\n",
      "Epoch 4/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3334 - val_loss: 0.3365\n",
      "Epoch 5/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3326 - val_loss: 0.3367\n",
      "Epoch 6/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3329 - val_loss: 0.3329\n",
      "Epoch 7/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3324 - val_loss: 0.3353\n",
      "Epoch 8/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3319 - val_loss: 0.3333\n",
      "Epoch 9/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3316 - val_loss: 0.3339\n",
      "Epoch 10/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3311 - val_loss: 0.3368\n",
      "f 3 acc: 0.7060777150448356\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./output/unitaryAI-dense-layer-v2/folds/model_0.7060777150448356_fold_3/assets\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 2304)]            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2304)              5310720   \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1152)              2655360   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 1153      \n",
      "=================================================================\n",
      "Total params: 7,967,233\n",
      "Trainable params: 7,967,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "753/753 [==============================] - 10s 12ms/step - loss: 0.3495 - val_loss: 0.3374\n",
      "Epoch 2/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3361 - val_loss: 0.3412\n",
      "Epoch 3/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3347 - val_loss: 0.3338\n",
      "Epoch 4/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3342 - val_loss: 0.3419\n",
      "Epoch 5/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3334 - val_loss: 0.3350\n",
      "Epoch 6/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3325 - val_loss: 0.3339\n",
      "Epoch 7/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3330 - val_loss: 0.3338\n",
      "Epoch 8/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3325 - val_loss: 0.3369\n",
      "Epoch 9/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3310 - val_loss: 0.3354\n",
      "Epoch 10/10\n",
      "753/753 [==============================] - 9s 12ms/step - loss: 0.3310 - val_loss: 0.3357\n",
      "f 4 acc: 0.7105612753238126\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ./output/unitaryAI-dense-layer-v2/folds/model_0.7105612753238126_fold_4/assets\n"
     ]
    }
   ],
   "source": [
    "k_folds = 5\n",
    "n_epochs = 10\n",
    "output_model_path = \"./output/unitaryAI-dense-layer-v2/folds/model_%s_%s\"\n",
    "kf = KFold(n_splits=k_folds, random_state=111, shuffle=True)\n",
    "for f, (train_index, test_index) in enumerate(kf.split(list(range(combined_output.shape[1])))):\n",
    "    combined_embeddings_train = CombinedEmbeddingGenerator(combined_output[0, train_index, :], combined_output[1, train_index, :]) # tr_ind\n",
    "    combined_embeddings_val = CombinedEmbeddingGenerator(combined_output[0, test_index, :], combined_output[1, test_index, :]) # val_ind\n",
    "\n",
    "    \n",
    "    siamese, tox_model = getModels()\n",
    "\n",
    "    history = siamese.fit(\n",
    "        combined_embeddings_train, # target inside it\n",
    "        validation_data=combined_embeddings_val,\n",
    "        epochs=n_epochs,\n",
    "    )\n",
    "\n",
    "    preds = np.zeros((len(val_ind), 2))\n",
    "    lastidx = 0\n",
    "    for batch in combined_embeddings_val:\n",
    "        less_tox, more_tox = batch[0][0], batch[0][1]\n",
    "        preds[lastidx: lastidx + len(less_tox), 0] = tox_model.predict(less_tox).squeeze(1)\n",
    "        preds[lastidx: lastidx + len(more_tox), 1] = tox_model.predict(more_tox).squeeze(1)\n",
    "        lastidx += len(less_tox)\n",
    "\n",
    "    acc = calculateAcc(preds[:, 0], preds[:, 1])\n",
    "    print(\"f\", f, \"acc:\", acc)\n",
    "    model_name = output_model_path%(str(acc), \"fold_\"+str(f))\n",
    "    tox_model.save(model_name)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a39880321af88786c208952b03056ebcfbeddf69d7aecdb8c75f75bacd597582"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('TOX_TF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
