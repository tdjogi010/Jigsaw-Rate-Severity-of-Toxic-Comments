{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-01-30T12:00:41.979932Z","iopub.status.busy":"2022-01-30T12:00:41.979517Z","iopub.status.idle":"2022-01-30T12:00:48.259044Z","shell.execute_reply":"2022-01-30T12:00:48.258293Z","shell.execute_reply.started":"2022-01-30T12:00:41.979820Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import transformers\n","from sklearn.kernel_approximation import Nystroem\n","from sklearn.svm import LinearSVR\n","import pickle\n","\n","from sklearn.model_selection import train_test_split\n","import gc\n","from sklearn.metrics import mean_squared_error\n","from sklearn.svm import SVR\n","from sklearn.decomposition import PCA"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:00:48.261165Z","iopub.status.busy":"2022-01-30T12:00:48.260765Z","iopub.status.idle":"2022-01-30T12:00:48.266402Z","shell.execute_reply":"2022-01-30T12:00:48.265626Z","shell.execute_reply.started":"2022-01-30T12:00:48.261125Z"},"trusted":true},"outputs":[],"source":["## Constants\n","target_key = \"score\"\n","text_key = \"txt\"\n","batch_size = 32\n","bert_path = \"bert-base-uncased\"\n","train_path = \"./train/civil_with_downsample.csv\"\n","lstm_hidden_dim = 64 # from 768 (bert) to 64  # the decrease is steep; u may lose info\n","dropout_rate = 0.3\n","output_dim = 1\n","max_length = 512\n","n_epochs = 1\n","# checkpoint_filepath = \"./bert/ckpt-loss={loss:.5f}-epoch={epoch}-batch={batch}\"\n","# final_train_filepath = \"./bert/final_model\"\n","save_after_batches = 5000\n","test_size_percent =  0.05\n","Nystroem_n_components = 1536 #3000 # dunno # using 1%\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:00:48.268009Z","iopub.status.busy":"2022-01-30T12:00:48.267526Z","iopub.status.idle":"2022-01-30T12:00:51.075515Z","shell.execute_reply":"2022-01-30T12:00:51.074788Z","shell.execute_reply.started":"2022-01-30T12:00:48.267973Z"},"trusted":true},"outputs":[],"source":["tokenizer = transformers.BertTokenizer.from_pretrained(bert_path, do_lower_case=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:00:51.077193Z","iopub.status.busy":"2022-01-30T12:00:51.076929Z","iopub.status.idle":"2022-01-30T12:00:51.083252Z","shell.execute_reply":"2022-01-30T12:00:51.080128Z","shell.execute_reply.started":"2022-01-30T12:00:51.077156Z"},"trusted":true},"outputs":[],"source":["# text = \"what's up?! ...... ðŸ¤—                 \\n\\t\" # space \\n \\t dont matter # emoji to [UNK] ! #punctuations are important/have indices\n","# text = \"I have a car. I've a car.\" # different indices but reconstructs fine\n","# print(text)\n","# input_ids = tokenizer.batch_encode_plus([text])[\"input_ids\"][0] # input_ids = [101, 2054, 1005, 1055, 2039, 1029, 102] \n","# print(input_ids)\n","# decoded = tokenizer.decode(input_ids)\n","# print(decoded)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:00:51.088525Z","iopub.status.busy":"2022-01-30T12:00:51.088334Z","iopub.status.idle":"2022-01-30T12:01:00.105102Z","shell.execute_reply":"2022-01-30T12:01:00.104449Z","shell.execute_reply.started":"2022-01-30T12:00:51.088502Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(1109778, 2)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["whole_df = pd.read_csv(train_path)\n","whole_df.shape"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:01:00.106756Z","iopub.status.busy":"2022-01-30T12:01:00.106496Z","iopub.status.idle":"2022-01-30T12:01:00.331862Z","shell.execute_reply":"2022-01-30T12:01:00.331142Z","shell.execute_reply.started":"2022-01-30T12:01:00.106721Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(339660, 2)\n"]},{"data":{"text/plain":["0.000000    53807\n","0.333333    49159\n","0.400000    33908\n","0.166667    13224\n","0.800000    12119\n","            ...  \n","0.204545        1\n","2.121622        1\n","3.771429        1\n","2.965517        1\n","1.528571        1\n","Name: score, Length: 8710, dtype: int64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["nontoxic_df = whole_df[whole_df[\"score\"] == 0] # 50%\n","toxic_df =  whole_df[whole_df[\"score\"] != 0] # 50 %\n","subset_df = pd.concat([nontoxic_df.sample(frac=0.1, random_state=23), toxic_df.sample(frac=0.5, random_state=24)], ignore_index=True) # ie 5% of whole (and non toxic) and 25% of whole( and toxic)\n","print(subset_df.shape) # 30% of whole\n","subset_df.score.value_counts()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:01:00.334091Z","iopub.status.busy":"2022-01-30T12:01:00.333826Z","iopub.status.idle":"2022-01-30T12:01:00.346083Z","shell.execute_reply":"2022-01-30T12:01:00.345200Z","shell.execute_reply.started":"2022-01-30T12:01:00.334055Z"},"trusted":true},"outputs":[],"source":["class CivilDataGenerator(tf.keras.utils.Sequence): # could optimize more like BucketIterator for padding\n","    def __init__(self, texts, scores, tokenizer, batch_size=batch_size, shuffle=True, include_targets=True): # texts -> numpy array\n","        self.texts = texts\n","        self.scores = scores\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        self.tokenizer =  tokenizer # \n","        self.indexes = np.arange(len(self.texts))\n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.texts) // self.batch_size + 1 if (len(self.texts) % self.batch_size) != 0 else 0\n","    \n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)\n","            \n","    def __getitem__(self, idx): # idx -> index batch\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        texts = self.texts[indexes]\n","        \n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            texts.tolist(), # num\n","            add_special_tokens=True, # not really needed in our case. \n","            max_length=max_length, # bert has 512 max length # providing our own\n","            return_attention_mask=True, # need bcos to pad to max length\n","            return_token_type_ids=False, # not needed # needed when u have two sentences\n","            padding='max_length', #pad_to_max_length=True, # needed\n","            return_tensors=\"tf\",\n","            truncation=True,\n","        )\n","        \n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        \n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            scores = np.array(self.scores[indexes], dtype=\"float32\")\n","            return [input_ids, attention_masks], scores\n","        else:\n","            return [input_ids, attention_masks]\n","        \n","        "]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:05:41.943282Z","iopub.status.busy":"2022-01-30T12:05:41.942985Z","iopub.status.idle":"2022-01-30T12:05:44.643914Z","shell.execute_reply":"2022-01-30T12:05:44.643195Z","shell.execute_reply.started":"2022-01-30T12:05:41.943244Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","attention_masks (InputLayer)    [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n","                                                                 attention_masks[0][0]            \n","__________________________________________________________________________________________________\n","global_average_pooling1d_1 (Glo (None, 768)          0           bert[0][0]                       \n","                                                                 attention_masks[0][0]            \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 768)          0           bert[0][0]                       \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 1536)         0           global_average_pooling1d_1[0][0] \n","                                                                 global_max_pooling1d_1[0][0]     \n","==================================================================================================\n","Total params: 109,482,240\n","Trainable params: 0\n","Non-trainable params: 109,482,240\n","__________________________________________________________________________________________________\n"]}],"source":["# Encoded token ids from BERT tokenizer.\n","input_ids = tf.keras.layers.Input(\n","    shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",")\n","# Attention masks indicates to the model which tokens should be attended to.\n","attention_masks = tf.keras.layers.Input(\n","    shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",")\n","\n","# Loading pretrained BERT model.\n","bert_model = transformers.TFBertModel.from_pretrained(bert_path)\n","# Freeze the BERT model to reuse the pretrained features without modifying them.\n","bert_model.trainable = False ## not training bert ##\n","\n","bert_output = bert_model.bert(input_ids, attention_mask=attention_masks) # by default hidden_size = 768\n","sequence_output = bert_output.last_hidden_state  # (batch_size, sequence_length, hidden_size) # ie each word representation \n","\n","avg_pool = tf.keras.layers.GlobalAveragePooling1D()(sequence_output, attention_masks) # averages over sequence length # (hidden_size)\n","max_pool = tf.keras.layers.GlobalMaxPooling1D()(sequence_output) # (batch_size, hidden_size)\n","concat = tf.keras.layers.concatenate([avg_pool, max_pool]) #(batch_size, hidden_size*2)\n","\n","model = tf.keras.models.Model(\n","    inputs=[input_ids, attention_masks], outputs=concat\n",")\n","\n","# doesnt matter compile\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(),\n","    loss= 'mse',# tf.keras.losses.MeanSquaredError(),\n","    metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.RootMeanSquaredError()],\n",")\n","\n","model.summary()"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:05:52.675949Z","iopub.status.busy":"2022-01-30T12:05:52.675683Z","iopub.status.idle":"2022-01-30T12:05:52.681012Z","shell.execute_reply":"2022-01-30T12:05:52.680256Z","shell.execute_reply.started":"2022-01-30T12:05:52.675918Z"},"trusted":true},"outputs":[],"source":["test_data = CivilDataGenerator(\n","    subset_df[text_key].values,\n","    None, # no target while inferring\n","    tokenizer,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    include_targets=False # added for inference\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-01-30T12:25:18.539523Z","iopub.status.busy":"2022-01-30T12:25:18.539011Z","iopub.status.idle":"2022-01-30T12:25:18.698720Z","shell.execute_reply":"2022-01-30T12:25:18.697618Z","shell.execute_reply.started":"2022-01-30T12:25:18.539477Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1, 512) (1, 512)\n","1/1 [==============================] - 0s 262ms/step\n","(1, 1536)\n","[[-0.12658632  0.13003351 -0.12224972 ...  0.05191765  0.73312306\n","   0.6112654 ]]\n"]}],"source":["for batch in test_data:\n","#     print(len(batch))# batch is list of [np.array(input_ids), p.array(attention_mask)] # each is (batch, ...)\n","    example = batch[0][0]\n","    mask = batch[1][0]\n","    example = example[np.newaxis, :]\n","    mask = mask[np.newaxis, :]\n","    # example[:,:] = 1000\n","    # mask[:,:] = 1\n","    print(example.shape, mask.shape)\n","#     print(example)\n","#     print(mask)\n","    embeddings = model.predict(\n","        [example, mask], #batch,\n","        use_multiprocessing=True, # can only be used when x, y are generators\n","        workers=-1,\n","        verbose=1\n","    )\n","    print(embeddings.shape)\n","    print(embeddings)\n","    break\n","# normal (no change) -> [[0.03166725 0.03764773 0.27967063 ... 1.0509706  1.3395917  1.1413577 ]]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.432864Z","iopub.status.idle":"2022-01-30T12:01:28.433420Z","shell.execute_reply":"2022-01-30T12:01:28.433199Z","shell.execute_reply.started":"2022-01-30T12:01:28.433172Z"},"trusted":true},"outputs":[],"source":["with tf.device('/device:GPU:0'):\n","    embeddings = model.predict(\n","        test_data,\n","        use_multiprocessing=True, # can only be used when x, y are generators\n","        workers=-1,\n","        verbose=1\n","    ) # whole takes 4:46:47 time and subset takes 1:28:00 time\n","\n","embeddings.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.434505Z","iopub.status.idle":"2022-01-30T12:01:28.435055Z","shell.execute_reply":"2022-01-30T12:01:28.434847Z","shell.execute_reply.started":"2022-01-30T12:01:28.434820Z"},"trusted":true},"outputs":[],"source":["with open('./bert-embeddings.npy', 'wb') as f:\n","    np.save(f, embeddings)\n","\n","y = subset_df[target_key].values\n","with open('./bert-embeddings-score.npy', 'wb') as f:\n","    np.save(f, y)\n","\n","subset_df.to_csv(\"subset_df.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.436143Z","iopub.status.idle":"2022-01-30T12:01:28.436713Z","shell.execute_reply":"2022-01-30T12:01:28.436485Z","shell.execute_reply.started":"2022-01-30T12:01:28.436461Z"},"trusted":true},"outputs":[],"source":["# with open('../input/jisaw-bert-svm-embedding-score-only/bert-embeddings.npy', 'rb') as f:\n","#     embeddings = np.load(f)\n","\n","# with open('../input/jisaw-bert-svm-embedding-score-only/bert-embeddings-score.npy', 'rb') as f:\n","#     y = np.load(f)\n","    \n","# embeddings.shape, y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.437772Z","iopub.status.idle":"2022-01-30T12:01:28.438314Z","shell.execute_reply":"2022-01-30T12:01:28.438098Z","shell.execute_reply.started":"2022-01-30T12:01:28.438075Z"},"trusted":true},"outputs":[],"source":["# pca_model = PCA(n_components=700) # not so great reduction in dimen\n","# pca_model.fit(embeddings)\n","# print(\"Sum of variance ratios: \",sum(pca_model.explained_variance_ratio_))\n","\n","# doing PCA first and then downsampling -> better PCA with more  embeddings I hope?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.439356Z","iopub.status.idle":"2022-01-30T12:01:28.439914Z","shell.execute_reply":"2022-01-30T12:01:28.439694Z","shell.execute_reply.started":"2022-01-30T12:01:28.439659Z"},"trusted":true},"outputs":[],"source":["# frac = 0.2\n","# n_samples = int(frac*len(embeddings))\n","# embeddings, y = embeddings[:n_samples], y[:n_samples]\n","# embeddings.shape, y.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.441003Z","iopub.status.idle":"2022-01-30T12:01:28.441560Z","shell.execute_reply":"2022-01-30T12:01:28.441355Z","shell.execute_reply.started":"2022-01-30T12:01:28.441330Z"},"trusted":true},"outputs":[],"source":["# tr_ind, val_ind = train_test_split(list(range(len(embeddings))) ,test_size = test_size_percent, random_state = 23)\n","# len(tr_ind), len(val_ind)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.442613Z","iopub.status.idle":"2022-01-30T12:01:28.443158Z","shell.execute_reply":"2022-01-30T12:01:28.442953Z","shell.execute_reply.started":"2022-01-30T12:01:28.442929Z"},"trusted":true},"outputs":[],"source":["# x_train = embeddings[tr_ind]\n","# y_train = y[tr_ind]\n","# x_test = embeddings[val_ind]\n","# y_test = y[val_ind]\n","# x_train.shape, y_train.shape, x_test.shape, y_test.shape\n","\n","# x_train =  pca_model.transform(embeddings[tr_ind]) \n","# y_train = y[tr_ind]\n","# x_test = pca_model.transform(embeddings[val_ind]) \n","# y_test = y[val_ind]\n","# x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.444209Z","iopub.status.idle":"2022-01-30T12:01:28.444776Z","shell.execute_reply":"2022-01-30T12:01:28.444553Z","shell.execute_reply.started":"2022-01-30T12:01:28.444529Z"},"trusted":true},"outputs":[],"source":["# pd.value_counts(y_train), pd.value_counts(y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.445822Z","iopub.status.idle":"2022-01-30T12:01:28.446368Z","shell.execute_reply":"2022-01-30T12:01:28.446147Z","shell.execute_reply.started":"2022-01-30T12:01:28.446123Z"},"trusted":true},"outputs":[],"source":["# del embeddings, y\n","# gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.447414Z","iopub.status.idle":"2022-01-30T12:01:28.447952Z","shell.execute_reply":"2022-01-30T12:01:28.447749Z","shell.execute_reply.started":"2022-01-30T12:01:28.447726Z"},"trusted":true},"outputs":[],"source":["# feature_map_nystroem = Nystroem(kernel = 'rbf', gamma=.2, random_state=23, n_components=Nystroem_n_components) #n_jobs=-1\n","# data_transformed = feature_map_nystroem.fit_transform(x_train)\n","# data_transformed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.449010Z","iopub.status.idle":"2022-01-30T12:01:28.449556Z","shell.execute_reply":"2022-01-30T12:01:28.449352Z","shell.execute_reply.started":"2022-01-30T12:01:28.449328Z"},"trusted":true},"outputs":[],"source":["# del x_train\n","# gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.450639Z","iopub.status.idle":"2022-01-30T12:01:28.451188Z","shell.execute_reply":"2022-01-30T12:01:28.450983Z","shell.execute_reply.started":"2022-01-30T12:01:28.450958Z"},"trusted":true},"outputs":[],"source":["# feature_map_nystroem.normalization_\n","# pickle.dump(feature_map_nystroem, open(\"./train/feature_map_nystroem\", 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.453027Z","iopub.status.idle":"2022-01-30T12:01:28.453580Z","shell.execute_reply":"2022-01-30T12:01:28.453378Z","shell.execute_reply.started":"2022-01-30T12:01:28.453353Z"},"trusted":true},"outputs":[],"source":["# regr = LinearSVR(random_state=0, tol=1e-5, loss=\"squared_epsilon_insensitive\")\n","# regr.fit(data_transformed, y_train)\n","\n","# regr = SVR(C=1.0, epsilon=0.2)\n","# regr.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.454622Z","iopub.status.idle":"2022-01-30T12:01:28.455172Z","shell.execute_reply":"2022-01-30T12:01:28.454969Z","shell.execute_reply.started":"2022-01-30T12:01:28.454944Z"},"trusted":true},"outputs":[],"source":["# pickle.dump(regr, open(\"./regr\", 'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.456245Z","iopub.status.idle":"2022-01-30T12:01:28.456794Z","shell.execute_reply":"2022-01-30T12:01:28.456578Z","shell.execute_reply.started":"2022-01-30T12:01:28.456553Z"},"trusted":true},"outputs":[],"source":["# data_transformed_test = feature_map_nystroem.transform(x_test)\n","# data_transformed_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-30T12:01:28.457830Z","iopub.status.idle":"2022-01-30T12:01:28.458378Z","shell.execute_reply":"2022-01-30T12:01:28.458159Z","shell.execute_reply.started":"2022-01-30T12:01:28.458134Z"},"trusted":true},"outputs":[],"source":["# print(regr.score(data_transformed_test, y_test))\n","# preds = regr.predict(data_transformed_test)\n","# mean_squared_error(y_test, preds)\n","\n","# print(regr.score(x_test, y_test))\n","# preds = regr.predict(x_test)\n","# mean_squared_error(y_test, preds)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":4}
