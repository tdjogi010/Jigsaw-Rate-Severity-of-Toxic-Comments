{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:02.964773Z","iopub.status.busy":"2022-01-26T00:59:02.964431Z","iopub.status.idle":"2022-01-26T00:59:09.380271Z","shell.execute_reply":"2022-01-26T00:59:09.379551Z","shell.execute_reply.started":"2022-01-26T00:59:02.96469Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import transformers\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from keras import backend as K"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:09.38238Z","iopub.status.busy":"2022-01-26T00:59:09.382131Z","iopub.status.idle":"2022-01-26T00:59:09.390088Z","shell.execute_reply":"2022-01-26T00:59:09.389352Z","shell.execute_reply.started":"2022-01-26T00:59:09.382345Z"},"trusted":true},"outputs":[],"source":["## Constants\n","target_key = \"score\"\n","text_key = \"txt\"\n","batch_size = 32\n","bert_path = \"bert-base-uncased\"\n","train_path = \"./train/civil_with_downsample.csv\"\n","lstm_hidden_dim = 64 # from 768 (bert) to 64  # the decrease is steep; u may lose info\n","dropout_rate = 0.3\n","output_dim = 1\n","max_length = 350\n","\n","checkpoint_filepath = \"./output/bert-2-bilstm-fine-tuning/ckpt-loss={loss:.5f}-epoch={epoch}-batch={batch}\"\n","final_train_filepath = \"./output/bert-2-bilstm-fine-tuning/bert/final_model\"\n","save_after_batches = 3000\n","test_size_percent =  0.05\n","\n","n_pass = 1\n","log_dir = \"./log/bert-2-bilstm-fine-tuning/\"\n","log_freq = 500 # batches\n","# n_steps_per_epoch = 500*15 # batches # val = 50k # 500*15 = 240k === persomerd after 5 times the val size\n","## improve # not worth\n","# total_batches = n_pass * len(train_data) # psuedo epoch to run  # len(train_data) gives batches\n","# n_epochs = total_batches//n_steps_per_epoch + 1 if total_batches%n_steps_per_epoch !=0 else 1\n","# print(total_batches, n_epochs)\n","n_epochs = 1\n","## \n","\n","\n","load_model_path = \"./output/bert-2-bilstm/bert/final_model\"# \"./train/jisawbert-1-bilstm-1-epoch/ckpt-loss0.14776-epoch1-batch30000\"\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:09.391735Z","iopub.status.busy":"2022-01-26T00:59:09.391343Z","iopub.status.idle":"2022-01-26T00:59:16.934847Z","shell.execute_reply":"2022-01-26T00:59:16.934175Z","shell.execute_reply.started":"2022-01-26T00:59:09.391696Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(1109778, 2)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["whole_df = pd.read_csv(train_path)\n","whole_df.shape"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:16.936431Z","iopub.status.busy":"2022-01-26T00:59:16.936184Z","iopub.status.idle":"2022-01-26T00:59:17.449202Z","shell.execute_reply":"2022-01-26T00:59:17.44826Z","shell.execute_reply.started":"2022-01-26T00:59:16.936398Z"},"trusted":true},"outputs":[],"source":["# tr_ind, val_ind = train_test_split(list(range(len(whole_df))) ,test_size = test_size_percent, random_state = 23)\n","# len(tr_ind), len(val_ind)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:17.452233Z","iopub.status.busy":"2022-01-26T00:59:17.451945Z","iopub.status.idle":"2022-01-26T00:59:17.456196Z","shell.execute_reply":"2022-01-26T00:59:17.455479Z","shell.execute_reply.started":"2022-01-26T00:59:17.452193Z"},"trusted":true},"outputs":[],"source":["# idx = whole_df[\"txt\"].str.len().idxmax() # split().len() # too slow\n","# max_length = len(whole_df[\"txt\"][idx].split())\n","# # max_length = max_length+10 # for safety \n","# max_length # 323 -> 350"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:17.458235Z","iopub.status.busy":"2022-01-26T00:59:17.457728Z","iopub.status.idle":"2022-01-26T00:59:18.626939Z","shell.execute_reply":"2022-01-26T00:59:18.626156Z","shell.execute_reply.started":"2022-01-26T00:59:17.458196Z"},"trusted":true},"outputs":[],"source":["class CivilDataGenerator(tf.keras.utils.Sequence): # could optimize more like BucketIterator for padding\n","    def __init__(self, texts, scores, tokenizer, batch_size=batch_size, shuffle=True, include_targets=True): # texts -> numpy array\n","        self.texts = texts\n","        self.scores = scores\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.include_targets = include_targets\n","        # Load our BERT Tokenizer to encode the text.\n","        self.tokenizer =  tokenizer # \n","        self.indexes = np.arange(len(self.texts))\n","        self.on_epoch_end()\n","        \n","    def __len__(self):\n","        # Denotes the number of batches per epoch.\n","        return len(self.texts) // self.batch_size + 1 if (len(self.texts) % self.batch_size) != 0 else 0\n","    \n","    def on_epoch_end(self):\n","        # Shuffle indexes after each epoch if shuffle is set to True.\n","        if self.shuffle:\n","            np.random.RandomState(42).shuffle(self.indexes)\n","            \n","    def __getitem__(self, idx): # idx -> index batch\n","        # Retrieves the batch of index.\n","        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n","        texts = self.texts[indexes]\n","        \n","        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n","        # encoded together and separated by [SEP] token.\n","        encoded = self.tokenizer.batch_encode_plus(\n","            texts.tolist(), # num\n","            add_special_tokens=True, # not really needed in our case. \n","            max_length=max_length, # bert has 512 max length # providing our own\n","            return_attention_mask=True, # need bcos to pad to max length\n","            return_token_type_ids=False, # not needed # needed when u have two sentences\n","            padding='max_length', #pad_to_max_length=True, # needed\n","            return_tensors=\"tf\",\n","            truncation=True,\n","        )\n","        \n","        # Convert batch of encoded features to numpy array.\n","        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n","        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n","        \n","        # Set to true if data generator is used for training/validation.\n","        if self.include_targets:\n","            scores = np.array(self.scores[indexes], dtype=\"float32\")\n","            return [input_ids, attention_masks], scores\n","        else:\n","            return [input_ids, attention_masks]\n","        \n","        \n","        "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:18.628827Z","iopub.status.busy":"2022-01-26T00:59:18.628559Z","iopub.status.idle":"2022-01-26T00:59:46.505987Z","shell.execute_reply":"2022-01-26T00:59:46.505168Z","shell.execute_reply.started":"2022-01-26T00:59:18.628792Z"},"trusted":true},"outputs":[],"source":["# Encoded token ids from BERT tokenizer.\n","# input_ids = tf.keras.layers.Input(\n","#     shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n","# )\n","# # Attention masks indicates to the model which tokens should be attended to.\n","# attention_masks = tf.keras.layers.Input(\n","#     shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n","# )\n","\n","# # Loading pretrained BERT model.\n","# bert_model = transformers.TFBertModel.from_pretrained(bert_path)\n","# # Freeze the BERT model to reuse the pretrained features without modifying them.\n","# bert_model.trainable = False ## not training bert ##\n","\n","# bert_output = bert_model.bert(input_ids, attention_mask=attention_masks) # by default hidden_size = 768\n","# sequence_output = bert_output.last_hidden_state  # (batch_size, sequence_length, hidden_size) # ie each word representation \n","\n","# ## for the warning we are good. not using pooled_output for now, https://github.com/huggingface/transformers/issues/5421\n","# # pooled_output = bert_output.pooler_output # (batch_size, hidden_size) # ie whole text representational (kinda)\n","\n","# # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n","# bi_lstm = tf.keras.layers.Bidirectional(\n","#     tf.keras.layers.LSTM(lstm_hidden_dim, return_sequences=True) \n","# )(sequence_output) # (batch_size,  sequence_length, lstm_hidden_dim*2) # merge_mode=\"concat\"\n","\n","# # bi_lstm = tf.keras.layers.Bidirectional(\n","# #     tf.keras.layers.LSTM(lstm_hidden_dim, return_sequences=True)\n","# # )(bi_lstm) # (batch_size,  sequence_length, lstm_hidden_dim*2) # stacked one more BiLSTM bcos with one stack its converging slowly (kind of plateau)\n","\n","# # Applying hybrid pooling approach to bi_lstm sequence output.\n","# avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm) # averages over sequence length # (batch_size, lstm_hidden_dim*2)\n","# max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm) # (batch_size, lstm_hidden_dim*2)\n","# concat = tf.keras.layers.concatenate([avg_pool, max_pool]) #(batch_size, lstm_hidden_dim*3)\n","# dropout = tf.keras.layers.Dropout(dropout_rate)(concat) #(batch_size, lstm_hidden_dim*3)\n","\n","# output = tf.keras.layers.Dense(output_dim)(dropout) # 1 since our target is 1 bcos regression \n","\n","\n","# model = tf.keras.models.Model(\n","#     inputs=[input_ids, attention_masks], outputs=output\n","# )\n","# model.compile(\n","#     optimizer=tf.keras.optimizers.Adam(),\n","#     loss= 'mse',# tf.keras.losses.MeanSquaredError(),\n","#     metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.RootMeanSquaredError()],\n","# )\n","\n","# model.summary()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:46.507949Z","iopub.status.busy":"2022-01-26T00:59:46.507285Z","iopub.status.idle":"2022-01-26T00:59:50.554827Z","shell.execute_reply":"2022-01-26T00:59:50.554053Z","shell.execute_reply.started":"2022-01-26T00:59:46.507909Z"},"trusted":true},"outputs":[],"source":["tokenizer = transformers.BertTokenizer.from_pretrained(bert_path, do_lower_case=True)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# resume # 21000/34681 and 3000/13681 was done => remaining = 13681 batches\n","# whole_df = whole_df[24000*batch_size:]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:50.556593Z","iopub.status.busy":"2022-01-26T00:59:50.556308Z","iopub.status.idle":"2022-01-26T00:59:52.254535Z","shell.execute_reply":"2022-01-26T00:59:52.253746Z","shell.execute_reply.started":"2022-01-26T00:59:50.556556Z"},"trusted":true},"outputs":[],"source":["train_data = CivilDataGenerator(\n","    whole_df[text_key].values,#whole_df[text_key][tr_ind].values, # not using validation data\n","    whole_df[target_key].values, #whole_df[target_key][tr_ind].values,\n","    tokenizer,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","# valid_data = CivilDataGenerator(\n","#     whole_df[text_key][val_ind].values,\n","#     whole_df[target_key][val_ind].values,\n","#     tokenizer,\n","#     batch_size=batch_size,\n","#     shuffle=False,\n","# )"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:52.256277Z","iopub.status.busy":"2022-01-26T00:59:52.25602Z","iopub.status.idle":"2022-01-26T00:59:52.263507Z","shell.execute_reply":"2022-01-26T00:59:52.26274Z","shell.execute_reply.started":"2022-01-26T00:59:52.256241Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["batch size 32\n","examples in train_data 1054289.0999999999\n","number of batches in training 32946.0\n"]}],"source":["# print(\"batch size\", batch_size)\n","# n_examples_train = (1-test_size_percent)*whole_df.shape[0]\n","# print(\"examples in train_data\", (1-test_size_percent)*whole_df.shape[0] )\n","# print(\"number of batches in training\", n_examples_train//batch_size )"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:52.265425Z","iopub.status.busy":"2022-01-26T00:59:52.264953Z","iopub.status.idle":"2022-01-26T00:59:52.2722Z","shell.execute_reply":"2022-01-26T00:59:52.271502Z","shell.execute_reply.started":"2022-01-26T00:59:52.265384Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-02-03 04:17:00.051460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:00.109700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:00.109944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:00.111082: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-02-03 04:17:00.111704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:00.111955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:00.112232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:01.075583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:01.075999: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:01.076014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2022-02-03 04:17:01.076378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:2b:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2022-02-03 04:17:01.076414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5420 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:2b:00.0, compute capability: 8.6\n"]}],"source":["# model = tf.keras.models.load_model('./bert/ckpt-loss=0.49327-epoch=1-batch=10') #model is around 479.4MB \n","# model.load_weights(load_model_path)\n","model = tf.keras.models.load_model(load_model_path)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<keras.saving.saved_model.load.Custom>TFBertMainLayer object at 0x7fa81d280340> True\n"]},{"data":{"text/plain":["<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=1e-05>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["## fine tuning ##\n","model.layers[2].trainable = True\n","print(model.layers[2], model.layers[2].trainable)\n","# for l in model.layers:\n","#     print(l, l.trainable) # BERT LAYER IS false\n","\n","\n","# dunno why compiling again is leading to OOM :/\n","# model.compile(\n","#     optimizer=tf.keras.optimizers.Adam(1e-5), # default is 0.001\n","#     loss= 'mse',# tf.keras.losses.MeanSquaredError(),\n","#     metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.RootMeanSquaredError()],\n","# )\n","\n","K.set_value(model.optimizer.learning_rate, 1e-5)\n","model.optimizer.learning_rate\n","# K.set_value(model.optimizer.learning_rate, 1e-5)\n","\n","\n","## fine tuning ## "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["34681"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data) # number of batches"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T00:59:52.273873Z","iopub.status.busy":"2022-01-26T00:59:52.27358Z","iopub.status.idle":"2022-01-26T01:00:15.647796Z","shell.execute_reply":"2022-01-26T01:00:15.645285Z","shell.execute_reply.started":"2022-01-26T00:59:52.273832Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-02-03 04:17:19.586042: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n","2022-02-03 04:17:19.586080: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n","2022-02-03 04:17:19.586934: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1614] Profiler found 1 GPUs\n","2022-02-03 04:17:19.587227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n","2022-02-03 04:17:19.625414: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n","2022-02-03 04:17:19.625557: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n","2022-02-03 04:17:19.717292: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2022-02-03 04:17:26.711991: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n","2022-02-03 04:17:28.128578: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"]},{"name":"stdout","output_type":"stream","text":["    1/34681 [..............................] - ETA: 87:07:51 - loss: 0.1210 - mean_squared_error: 0.1210 - root_mean_squared_error: 0.3479"]},{"name":"stderr","output_type":"stream","text":["2022-02-03 04:17:29.071666: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n","2022-02-03 04:17:29.071712: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n"]},{"name":"stdout","output_type":"stream","text":["    2/34681 [..............................] - ETA: 15:00:51 - loss: 0.1129 - mean_squared_error: 0.1129 - root_mean_squared_error: 0.3360"]},{"name":"stderr","output_type":"stream","text":["2022-02-03 04:17:30.342916: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n","2022-02-03 04:17:30.343145: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n","2022-02-03 04:17:30.365388: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 7144 callback api events and 7178 activity events. \n","2022-02-03 04:17:30.422742: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n","2022-02-03 04:17:30.485055: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30\n","\n","2022-02-03 04:17:30.541983: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.trace.json.gz\n","2022-02-03 04:17:30.608203: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30\n","\n","2022-02-03 04:17:30.615624: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.memory_profile.json.gz\n","2022-02-03 04:17:30.629980: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30\n","Dumped tool data for xplane.pb to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.xplane.pb\n","Dumped tool data for overview_page.pb to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.overview_page.pb\n","Dumped tool data for input_pipeline.pb to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.input_pipeline.pb\n","Dumped tool data for tensorflow_stats.pb to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.tensorflow_stats.pb\n","Dumped tool data for kernel_stats.pb to ./log/bert-2-bilstm-fine-tuning/train/plugins/profile/2022_02_03_04_17_30/DESKTOP-KPOCLK7.kernel_stats.pb\n","\n"]},{"name":"stdout","output_type":"stream","text":[" 3000/34681 [=>............................] - ETA: 6:21:01 - loss: 0.1111 - mean_squared_error: 0.1111 - root_mean_squared_error: 0.3333"]},{"name":"stderr","output_type":"stream","text":["2022-02-03 04:53:40.167291: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.11108-epoch=1-batch=3000/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.11108-epoch=1-batch=3000/assets\n"]},{"name":"stdout","output_type":"stream","text":[" 6000/34681 [====>.........................] - ETA: 5:45:05 - loss: 0.1102 - mean_squared_error: 0.1102 - root_mean_squared_error: 0.3320"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.11019-epoch=1-batch=6000/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.11019-epoch=1-batch=6000/assets\n"]},{"name":"stdout","output_type":"stream","text":["18000/34681 [==============>...............] - ETA: 3:19:39 - loss: 0.1100 - mean_squared_error: 0.1100 - root_mean_squared_error: 0.3317"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.11003-epoch=1-batch=18000/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.11003-epoch=1-batch=18000/assets\n"]},{"name":"stdout","output_type":"stream","text":["24000/34681 [===================>..........] - ETA: 2:07:50 - loss: 0.1099 - mean_squared_error: 0.1099 - root_mean_squared_error: 0.3316"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.10993-epoch=1-batch=24000/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.10993-epoch=1-batch=24000/assets\n"]},{"name":"stdout","output_type":"stream","text":["27000/34681 [======================>.......] - ETA: 1:31:56 - loss: 0.1099 - mean_squared_error: 0.1099 - root_mean_squared_error: 0.3315"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.10986-epoch=1-batch=27000/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/ckpt-loss=0.10986-epoch=1-batch=27000/assets\n"]},{"name":"stdout","output_type":"stream","text":["34681/34681 [==============================] - 24911s 718ms/step - loss: 0.1099 - mean_squared_error: 0.1099 - root_mean_squared_error: 0.3316\n"]},{"name":"stderr","output_type":"stream","text":["2022-02-03 11:12:31.026802: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2812907520 exceeds 10% of free system memory.\n","WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/bert/final_model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ./output/bert-2-bilstm-fine-tuning/bert/final_model/assets\n"]}],"source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq=log_freq)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    monitor= 'loss',#'val_loss',\n","    save_freq=save_after_batches, # save after x batches\n","#     save_weights_only=True # aroud 444MB # not saving much\n","    save_best_only=True, # to save some space\n","    mode=\"min\", # for loss\n",")\n","\n","with tf.device('/device:GPU:0'):\n","# batch_size is used in generators so not specified here\n","    history = model.fit(\n","        train_data,\n","        # validation_data=valid_data, \n","        epochs=n_epochs,\n","        use_multiprocessing=True, # can only be used when x, y are generators\n","        workers=-1,\n","        # steps_per_epoch=n_steps_per_epoch,\n","        callbacks=[model_checkpoint_callback, tensorboard_callback],\n","    )\n","    model.save(final_train_filepath)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.status.busy":"2022-01-26T01:00:15.650354Z","iopub.status.idle":"2022-01-26T01:00:15.652499Z","shell.execute_reply":"2022-01-26T01:00:15.652263Z","shell.execute_reply.started":"2022-01-26T01:00:15.652235Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'loss': [0.10993647575378418],\n"," 'mean_squared_error': [0.10993647575378418],\n"," 'root_mean_squared_error': [0.3315666913986206]}"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["history.history"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2022-01-26T01:00:15.657259Z","iopub.status.idle":"2022-01-26T01:00:15.658085Z","shell.execute_reply":"2022-01-26T01:00:15.657887Z","shell.execute_reply.started":"2022-01-26T01:00:15.657864Z"},"trusted":true},"outputs":[],"source":["# from tensorflow.python.client import device_lib\n","# print(device_lib.list_local_devices())\n","# tf.config.list_physical_devices('GPU')[0].name"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# finetune bert \n","# use tfidf in ensemble\n","# figure out why enmsemble is not working\n","# debug where model is predicting wrong from validation data"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.9"}},"nbformat":4,"nbformat_minor":4}
